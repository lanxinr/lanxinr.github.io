# AI-Integrated Physics Lab Scenario

## 1. Scenario description

The instructor noticed that many students could perform calculations but struggle to explain why their results differ from theoretical predictions. With only limited TA support, providing individualized feedback on reasoning becomes difficult. This challenge motivated the integration of an AI tutor into weekly lab sessions. This case takes place in a **3-credit, calculus-based introductory physics course** for undergraduate students (e.g., engineering or life science majors). The course meets:

- **Two 75-minute lectures per week**, and
- **One weekly 50–60-minute lab/recitation session**.

### Lectures

In lectures, the instructor:

- **Delivers core conceptual knowledge**, such as forces and motion, energy and momentum conservation, and simple harmonic motion.
- **Models problem-solving approaches** by:
  - Identifying which principles apply in a given situation,
  - Demonstrating how to construct diagrams and equations,
  - Checking units, magnitudes, and physical reasonableness of answers.

Lectures focus on building students' **conceptual understanding** and **general problem-solving frameworks**.

### Weekly 1-hour lab / recitation

The weekly 1-hour lab provides a **compact, real-context space** to help students:

- Apply lecture concepts to concrete situations (e.g., cart collisions, spring–mass systems),
- Work with simplified or pre-structured experiments,
- Analyze real or realistic data sets,
- Practice problem solving in contexts closely aligned with lecture topics.

Because time is limited, labs often use:

- **Pre-configured setups** (apparatus and sensors already arranged), and/or
- **Pre-collected or simulated data**, so students can focus on interpretation and problem solving.

During the **central portion (about 20–25 minutes)** of each lab, students work individually with an **AI tutor (e.g., ChatGPT, Claude, Gemini, Khanmigo)** on laptops, tablets, or lab computers. After this first introduction, the course simply refers to it as **the AI tutor**. Throughout the scenario, the AI tutor functions as a questioning partner rather than an answer generator.

The AI tutor is designed using **research-based tutoring principles**. It:

- Scaffolds multi-step problems into manageable steps,
- Prompts students to explain their reasoning before providing hints,
- Manages cognitive load by pacing and chunking information,
- Uses growth-mindset language and provides targeted, timely feedback.

Across the **entire semester**, students:

- Use the AI tutor during most weekly lab sessions to analyze data and solve related problems,
- Take **lab tests without AI** at key points to demonstrate independent problem-solving ability,
- Complete **mid-semester and end-of-semester reflections** on how AI has supported their learning and what "meaningful use of AI" looks like in their physics studies.

## 2. Learning objectives

By the end of the AI-integrated lab sequence, students will be able to:

### Physics content and practices

1. **Apply** core mechanics concepts (e.g., Newton's laws, conservation of energy, conservation of momentum) to analyze experimental situations and solve multi-step quantitative problems.
2. **Interpret and connect** multiple representations of physical phenomena (graphs, equations, diagrams, and verbal descriptions) derived from lab contexts.
3. **Design and justify** solution strategies for novel physics problems, explaining their reasoning step-by-step.

### Use of AI for learning

4. **Use the AI tutor strategically** to:
   - Ask targeted questions about concepts and procedures,
   - Request hints rather than full solutions,
   - Check and refine their own reasoning and calculations.
5. **Critically evaluate** AI-generated explanations and solutions, identifying errors, gaps, or oversimplifications and reconciling them with physics principles and experimental evidence.

### Metacognition and reflection

6. **Reflect on and articulate** how the AI tutor has supported or hindered their learning over time, including effects on conceptual understanding, problem-solving strategies, motivation, and confidence.
7. **Formulate personal guidelines** for meaningful and ethical use of AI in their own learning, especially in STEM contexts.

## 3. AI-integrated lab activities

Labs provide an ideal environment for AI-supported reasoning because students work with real data, encounter inconsistencies, and need immediate feedback that instructors cannot provide to all students at once. Each weekly lab is about **50–60 minutes**, so the design emphasizes **tight structure and depth over breadth**:

- 5–10 minutes: Brief check-in and setup
- 15–20 minutes: Quick experiment or data exploration (group)
- 20–25 minutes: AI-supported analysis and problem solving (individual)
- 5 minutes: Micro-reflection and wrap-up

### 3.1 Pre-lab (asynchronous, short)

To maximize lab time, students complete a brief pre-lab online:

- **Pre-lab conceptual check**  
  3–5 short questions related to the week's lecture topic (e.g., momentum conservation, work–energy), ensuring students arrive with a basic grasp of relevant lecture material.
- **Optional example of effective AI use**  
  A short transcript showing a student sharing their own attempt, asking the AI tutor for feedback on reasoning, and receiving hints rather than a complete solution.

### 3.2 In-lab Phase 1 (≈15–20 minutes): Quick experiment or data exploration

In small groups (2–3 students), they:

- Work with **pre-configured setups** (e.g., carts on a track, spring–mass system) or examine **clean data sets** provided by the instructor.
- Make a brief prediction, such as:
  - "Should total momentum be approximately the same before and after this collision?"
  - "How should mechanical energy change over one oscillation?"
- Run a small number of trials or inspect the provided data:
  - Confirm basic behaviors,
  - Record key values (e.g., velocities, periods, amplitudes).
- Connect to lecture by briefly discussing how the observed behavior matches or challenges expectations based on lecture concepts.

The aim is to give a **concrete, real-world anchor** for lecture concepts without consuming the entire lab time on setup and raw data collection.

### 3.3 In-lab Phase 2 (≈20–25 minutes): AI-supported analysis and problem solving (individual)

#### Activity A – Focused data interpretation with the AI tutor

Each student:

- Enters a small set of key values (e.g., masses and velocities for a collision, or amplitude and period for a spring–mass system) into a worksheet or online form.
- Works through a **short, scaffolded sequence** of tasks, such as:
  - *Conceptual recap:* "According to lecture, what quantity (or quantities) should be conserved in this system? Explain briefly."
  - *Calculation:* "Use the data to calculate total momentum before and after the collision."
  - *Comparison and explanation:* "Compare your experimental values with the theoretical expectation. Ask the AI tutor to help you reason about possible sources of discrepancy (e.g., friction, imperfect collisions, measurement issues)."

The AI tutor:

- Prompts students to **show their reasoning first**,
- Provides **targeted hints** ("Check the sign of this velocity," "Are you including all objects in your system?"),
- Helps students connect **lecture principles** to **lab realities** such as uncertainty and non-ideal conditions.

#### Activity B – Single transfer problem with AI support

Time allows for **one well-designed transfer problem** per lab:

- Uses the same core concept as the lab/lecture (e.g., conservation of momentum or energy) but in a **new context** (different parameters, modified setup, or an everyday scenario).

Students:

- **Outline a solution plan** in their own words (1–3 bullet points):
  - Which principle(s) they will use,
  - What diagrams or representations they will construct,
  - What they need to solve for.
- Show this plan to the AI tutor and ask it to **evaluate the plan** (e.g., "Does this plan correctly apply conservation of momentum?").
- Execute the plan, then ask the AI tutor to:
  - Check the logic of their steps,
  - Help interpret the result (e.g., "Is this speed physically reasonable?"),
  - Suggest alternative approaches or ways to think about the problem.

This gives each student **individualized, immediate feedback** closely tied to lecture ideas, but in a context where they can pause, re-try, and ask questions.

### 3.4 Micro-reflection (≈5 minutes)

At the end of lab, students complete a very short reflection, such as:

- "Name one idea from lecture that became clearer after today's lab and AI work."
- "In one or two sentences, describe a way the AI tutor helped—or did not help—your understanding today."

These micro-reflections are quick to complete and review, provide students with accumulated notes for later reflections, and give instructors ongoing feedback about how the AI tutor is being used and perceived.

## 4. Evaluation description (lab test and reflection)

### 4.1 Lab test (problem-solving assessment)

To determine whether AI-supported lab work improves **independent** problem-solving, students complete lab tests (e.g., at midterm and end-of-semester) **without the AI tutor**. These tests can be given during lecture time, in a scheduled exam block, or via a proctored online system.

Each lab test includes:

- **Conceptual items**:
  - Multiple-choice and short-answer questions about lab-like contexts,
  - Tasks that ask students to interpret graphs, explain phenomena, and predict qualitative outcomes based on principles discussed in lecture and experienced in lab.
- **Multi-step quantitative problems**:
  - Structurally similar to AI-supported lab problems but with new parameters or contexts (e.g., a novel collision or mass–spring configuration),
  - Requiring students to identify relevant principles, set up diagrams and equations, perform calculations, and interpret results.

The lab test provides evidence of **AI-free mastery** of the types of problems students practiced with AI support.

### 4.2 Reflection assignment

Students also complete a **mid-semester reflection** after several weeks of AI-integrated labs and an **end-of-semester reflection** synthesizing their overall experience.

Sample prompts include:

- **Learning with AI in lab**: Describe two specific moments when the AI tutor helped you overcome a conceptual or problem-solving difficulty in lab. How did your understanding or strategy change?
- **Critical stance toward AI**: Describe a time when the AI tutor's response was confusing, incomplete, or incorrect. How did you recognize this, and what did you do to resolve it?
- **Strategy development over time**: How has your strategy for using the AI tutor changed from the first few labs to now? Provide concrete examples.
- **Meaningful use of AI in your learning**: Based on your semester-long experience, what does "meaningful use of AI" in physics learning mean to you? Give at least two examples from lab.
- **Personal guidelines for future AI use**: List 2–3 personal rules you plan to follow when using AI to support your learning in future courses.

## 5. Evaluation method for lab test and reflection

### 5.1 Lab test scoring (example scheme)

**Section A: Conceptual understanding (40%)**

Each conceptual item is scored on:

- **Correctness** of the answer (e.g., 0–2 points),
- **Quality of explanation** (e.g., 0–2 points), considering appropriate use of physics principles, clear reasoning, and effective diagrams or graphs when relevant.

**Section B: Quantitative problem solving (60%)**

Each multi-step problem is scored using three criteria (e.g., 0–3 points each):

- **Problem representation and setup**:
  - Correct diagrams and identification of the system,
  - Proper choice of relevant laws (e.g., Newton's laws, conservation of energy or momentum).
- **Procedural accuracy**:
  - Correct algebraic manipulation,
  - Correct and consistent units,
  - Reasonable intermediate and final numerical results.
- **Interpretation and sense-making**:
  - Checks whether results are physically plausible,
  - Connects results back to the physical context and, where appropriate, similar lab experiences,
  - Explains what the result means in plain language.

Scores are combined into a total percentage and mapped onto performance categories such as *Excellent*, *Proficient*, *Developing*, and *Beginning*.

### 5.2 Reflection rubric (4-point scale per dimension)

**Table 1. Reflection Rubric for AI-Supported Physics Lab Learning**

| Dimension | 4 – Exemplary | 3 – Proficient | 2 – Developing | 1 – Beginning |
|-----------|---------------|----------------|-----------------|----------------|
| **Depth of reflection on learning with AI tutor** | Rich, specific examples; clearly explains how AI interactions changed understanding or strategies. | Some specific examples; learning explained reasonably clearly. | Mostly general statements; few or vague examples; limited explanation of learning. | Very general or superficial; little or no evidence of learning. |
| **Critical evaluation of AI** | Identifies strengths and limitations of AI responses with clear evidence; shows nuanced judgment. | Recognizes some limitations and strengths; at least one clear example. | Mentions limitations or strengths with minimal detail. | Little or no critical stance; treats AI as always right or always wrong. |
| **Use of evidence from lab experiences** | Integrates multiple concrete references to specific lab tasks, data, or problems. | Includes at least one concrete reference to lab experiences. | References to lab experiences are vague or minimal. | No clear connection to specific lab activities. |
| **Metacognitive insight / strategy development** | Articulates clear, evolving strategies for using AI; connects strategies to personal learning goals. | Describes some strategies for using AI and how they help. | Mentions strategies but does not explain why they matter. | Little or no discussion of strategies; mainly describes what AI did. |
| **Clarity and organization** | Well-organized, coherent, and polished; language/mechanics do not hinder understanding. | Mostly clear and organized; minor issues only. | Organization uneven; some parts hard to follow; noticeable mechanical issues. | Disorganized or difficult to follow; frequent errors hinder understanding. |

## 6. Guidelines for faculty

### Design and setup

- **Align AI-supported lab tasks with lecture content.**  
  Use lab topics and problems that give students a chance to apply the specific concepts and problem-solving approaches modeled in lecture.
- **Align AI tutor prompts with learning goals.**  
  Design or model prompts that ask students to share their reasoning first, emphasize hints and explanations over full solutions, and encourage connections between AI feedback, lecture ideas, and lab observations.
- **Structure lab for a short time window.**  
  Use pre-configured setups or pre-collected data, limit labs to a small number of focused tasks plus one transfer problem, and keep instructions clear to leave time for thinking and reflection.

### Implementation in lab

- **Clarify when AI is allowed vs. not allowed.**  
  Explicitly specify lab activities where AI is encouraged (analysis, practice problems, sense-making) and assessments where AI is not allowed (lab tests, exams, certain graded tasks).
- **Model meaningful AI use.**  
  Show examples of good questions that deepen understanding, less productive "answer-only" questions, and how to respond when AI provides an incorrect or confusing answer.
- **Monitor and coach student–AI interactions.**  
  Walk around during AI use, ask what students asked the AI and how the response changed their thinking, encourage refined prompts, and address over-reliance on AI solutions.

### Ethics, equity, and access

- **Ensure equitable access.**  
  Provide appropriate hardware and software access in the lab and make sure all students can use the AI tutor reliably.
- **Discuss academic integrity and responsible AI use.**  
  Co-create norms about appropriate vs. inappropriate uses of AI, when and how to acknowledge AI assistance, and expectations for independent work on tests and certain assignments.
- **Use reflection data to improve teaching.**  
  Read a sample of reflections mid-semester to identify patterns of productive and unproductive AI use, adjust lab activities and guidance accordingly, and share anonymized examples of effective AI use with the class.

## 7. Guidelines for students

### Using AI to learn physics (not just get answers)

- **Begin with your own thinking.**  
  Before using the AI tutor, quickly jot down which concept from lecture you think applies, a diagram or representation, and your first attempt at a solution or plan. Then show this to the AI tutor and ask it to check or refine your reasoning.
- **Ask focused, learning-oriented questions.**  
  For example: "Can you help me see if I used conservation of momentum correctly in this step?" or "I'm confused why kinetic energy changes even though momentum is conserved. Can you explain?"
- **Request hints, reasoning, and explanations before answers.**  
  Ask for next-step hints, clarification of specific parts you don't understand, and alternative ways to think about the same problem.

### Thinking critically about AI responses

- **Always verify with physics.**  
  Check AI responses against lecture notes, textbook explanations, equations and methods you've been taught, units and magnitudes, and your lab data where relevant.
- **Challenge confusing or suspicious output.**  
  If something doesn't make sense, ask the AI tutor to restate or reconsider, compare with your own understanding or ask your partner/TA, and treat the AI tutor as a helpful but imperfect tool.

### Habits over the semester

- **Track your use of the AI tutor.**  
  After each lab, note briefly one way the AI tutor helped you understand lecture material better and one limitation or problem you noticed. Use these notes for your mid-semester and final reflections.
- **Develop personal AI-use guidelines.**  
  Over time, decide on 2–3 personal rules, such as: "I will attempt each problem by myself for at least 5–10 minutes before asking the AI tutor," "I will not copy AI text directly into any graded work," or "I will use AI to understand why a solution works, not just to get an answer."

### Integrity and professionalism

- **Be honest about AI use.**  
  Follow the course rules about where and when AI is allowed. If you used AI to help with wording or to check reasoning, be transparent and make sure the underlying physics is your own.
- **Use AI to become a stronger problem solver.**  
  Regularly ask yourself: "If AI disappeared tomorrow, could I solve a similar problem on my own?" Aim to use the AI tutor as a support for your learning, not a substitute for your thinking.

## 8. Reference

Kestin, G., Miller, K., Klales, A., Milbourne, T., & Ponti, G. (2025).  
AI tutoring outperforms in-class active learning: An RCT introducing a novel research-based design in an authentic educational setting.  
*Scientific Reports, 15*, 17458. https://doi.org/10.1038/s41598-025-97652-6

